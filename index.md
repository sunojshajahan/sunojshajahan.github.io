---
title: ""
---

<!-- ![](./new_images/Lab_group_photo_030325.jpg#right)

### Assistant Professor (Digital Precision Agriculture) <br>
[Agricultural and Biological Engineering](https://abe.illinois.edu/directory/sunoj), <br>
University of Illinois Urbana-Champaign, Urbana, IL 61801. <br>
Email: sunoj[at]illinois.edu <br>

# [![GitHub](https://img.shields.io/badge/GitHub-000?style=flat&logo=github)](https://github.com/sunojshajahan)     [![Twitter](https://img.shields.io/badge/Twitter-1DA1F2?style=flat&logo=twitter)](https://twitter.com/sunojshajahan)  [![ResearchGate](https://img.shields.io/badge/ResearchGate-0cb?style=flat&logo=researchgate)](https://www.researchgate.net/profile/Sunoj-Shajahan-2)     -->

<!-- [Sunoj Shajahan CV](SunojCV_October10_2022.pdf) -->
# Welcome to the Digital Precision Agriculture Lab!  

![](./images/Lab_group_photo_030325.jpg)
<p style="text-align: center;"> <em>The strength of the team is each individual member. The strength of each member is the team - Phil Jackson</em> </p>


The **Digital Precision Agriculture Lab** is located in **Room #236** of the [Agricultural Engineering Sciences Building](https://maps.app.goo.gl/RmhaJGFe6cYfWJEN7) at the [Department of Agricultural and Biological Engineering](https://abe.illinois.edu/), University of Illinois Urbana-Champaign. Here, we specialize in **Computational Engineering for Digital Precision Agriculture**.  

We focus on both **fundamental and applied research**, maintaining a balance between theoretical exploration and practical implementation. Each project has its unique scope, ranging from **exploratory analysis based on theoretical principles** to the **real-time application of using robotic platforms** and other advanced agricultural technologies.  

Our research focuses on using **advanced data analytics** and **AI algorithms** ranging from simple models to state-of-the-art (SOTA) techniques—to process and interpret multi-source sensor data. These data streams include:  
- **Remotely sensed imagery** (using free and open-access platforms),  
- **Robotics sensing data** (collected using the Farm-ng Amiga platform), and  
- **Machine sensing** (from vision cameras mounted on agricultural equipment).  

We are dedicated to developing **data-driven decision support tools** that empower farmers and stakeholders to make informed decisions, whether for seasonal management, understanding legacy effects, or enabling near real-time interventions. By bridging the gap between technology and agriculture, we aim to create innovative, practical, and impactful solutions that address the challenges of modern agriculture.  

## Passion for open source in agriculture

Our team is passionate about utilizing **Free and Open-Source Software (FOSS)** platforms for computer vision, geospatial analysis, and software tool development. We focus on designing workflows for analyzing images or any data formats from vision cameras or remotely sensed images using FOSS tools such as **QGIS**, **R**, **ImageJ**, and **Python**. We believe that the open-source culture promotes widespread access, fosters transparency, reproducibility, and ensures credibility and practicality for farmers and researchers.  

<!-- Thank you for visiting! Explore our website to learn more about our **research areas**, meet our talented **team members**, and discover our **publications**, **awards**, and **events**. Together, we’re working toward a smarter, more sustainable future for agriculture.   -->

---

## Lab Updates  

+ **March 2025**: Our team is excited to participate in the [Farm Robotics Challenge 2025](https://www.farmroboticschallenge.ai/2025), organized by UC Agriculture and Natural Resources and the AI Institute for Next Generation Food Systems (AIFS), with support from the Fresno-Merced Future of Food Initiative (F3).

+ **February 2025**: Our talented team member, [Pavan Kumar Dabilpuram](https://www.linkedin.com/in/pkd999/), has joined **Analog Devices** in Wilmington, MA. We are proud of his contributions to our lab and wish him the very best in this exciting new chapter!  

---